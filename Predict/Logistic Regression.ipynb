{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Logistic Regression.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMY/GPcdE0XYRycOqr9Wpgc"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"KNlyDypGynwe","colab_type":"code","outputId":"9dae1346-741c-4f2e-af1f-90805f567192","executionInfo":{"status":"ok","timestamp":1585665337711,"user_tz":-480,"elapsed":24040,"user":{"displayName":"Xinlong Li","photoUrl":"","userId":"00115760002936130732"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dn7Gj0GU1Tzv","colab_type":"code","colab":{}},"source":["import os\n","os.chdir(\"/content/gdrive/My Drive/MyAnn\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U_vB5kvG9FAM","colab_type":"code","outputId":"3c553c97-d5b1-41a8-def4-ee301bb4fee8","executionInfo":{"status":"ok","timestamp":1585667772971,"user_tz":-480,"elapsed":22865,"user":{"displayName":"Xinlong Li","photoUrl":"","userId":"00115760002936130732"}},"colab":{"base_uri":"https://localhost:8080/","height":581}},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from scipy.sparse import csr_matrix, hstack\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from scipy.sparse import vstack\n","\n","\n","datadir = '/content/gdrive/My Drive/MyAnn/Data'\n","data = pd.read_csv(os.path.join(datadir,'gender_age_train.csv'),index_col='device_id')\n","phone = pd.read_csv(os.path.join(datadir,'phone_brand_device_model.csv'))\n","\n","# Get rid of duplicate device ids in phone\n","phone = phone.drop_duplicates('device_id',keep='first').set_index('device_id')\n","\n","events = pd.read_csv(os.path.join(datadir,'events.csv'),parse_dates=['timestamp'], index_col='event_id')\n","appevents = pd.read_csv(os.path.join(datadir,'app_events.csv'),usecols=['event_id','app_id','is_active'],dtype={'is_active':bool})\n","applabels = pd.read_csv(os.path.join(datadir,'app_labels.csv'))\n","\n","gatrain, gatest, y_train, y_test = train_test_split(data, data['group'], test_size=0.33, random_state=42)\n","\n","gatrain['trainrow'] = np.arange(gatrain.shape[0])\n","gatest['testrow'] = np.arange(gatest.shape[0])\n","\n","# feature engineering\n","\n","# phone brand\n","\n","# encoding\n","brandencoder = LabelEncoder().fit(phone.phone_brand)\n","phone['brand'] = brandencoder.transform(phone['phone_brand'])\n","gatrain['brand'] = phone['brand']\n","gatest['brand'] = phone['brand']\n","\n","# For phone brand data the data array will be all ones, row_ind will be the row number of a device \n","# and col_ind will be the number of brand\n","\n","Xtr_brand = csr_matrix((np.ones(gatrain.shape[0]),(gatrain.trainrow, gatrain.brand)))\n","Xte_brand = csr_matrix((np.ones(gatest.shape[0]),(gatest.testrow, gatest.brand)))\n","\n","# device model\n","# concatenating phone brand and device model\n","m = phone.phone_brand.str.cat(phone.device_model)\n","\n","# encoding\n","modelencoder = LabelEncoder().fit(m)\n","phone['model'] = modelencoder.transform(m)\n","gatrain['model'] = phone['model']\n","gatest['model'] = phone['model']\n","\n","# For device model data the data array will be all ones, row_ind will be the row number of a device \n","# and col_ind will be the number of brand-device model\n","\n","Xtr_model = csr_matrix((np.ones(gatrain.shape[0]),(gatrain.trainrow, gatrain.model)))\n","Xte_model = csr_matrix((np.ones(gatest.shape[0]),(gatest.testrow, gatest.model)))\n","\n","# active apps\n","# merge device_id column from events table to app_events\n","# group the resulting dataframe by device_id and app and aggregate\n","# merge in trainrow and testrow columns to know at which row to put each device in the features matrix\n","\n","# encoding apps\n","appencoder = LabelEncoder().fit(appevents.app_id)\n","appevents['app'] = appencoder.transform(appevents.app_id)\n","\n","napps = len(appencoder.classes_)\n","\n","# merging tables\n","deviceapps = (appevents.merge(events[['device_id']], how='left',left_on='event_id',right_index=True)\n","                       .groupby(['device_id','app'])['app'].agg(['size'])\n","                       .merge(gatrain[['trainrow']], how='left', left_index=True, right_index=True)\n","                       .merge(gatest[['testrow']], how='left', left_index=True, right_index=True)\n","                       .reset_index())\n","\n","# building a feature matrix where the data is all ones, row_ind comes from trainrow or testrow \n","# and col_ind is the label-encoded app_id\n","d = deviceapps.dropna(subset=['trainrow'])\n","Xtr_app = csr_matrix((np.ones(d.shape[0]), (d.trainrow, d.app)),shape=(gatrain.shape[0],napps))\n","\n","d = deviceapps.dropna(subset=['testrow'])\n","Xte_app = csr_matrix((np.ones(d.shape[0]), (d.testrow, d.app)),shape=(gatest.shape[0],napps))\n","\n","# app labels\n","# constructed in a way similar to apps features by merging app_labels with the \n","# deviceapps dataframe we created above\n","applabels = applabels.loc[applabels.app_id.isin(appevents.app_id.unique())]\n","\n","# encoding apps in app labels\n","applabels['app'] = appencoder.transform(applabels.app_id)\n","\n","# encoding app labels\n","labelencoder = LabelEncoder().fit(applabels.label_id)\n","applabels['label'] = labelencoder.transform(applabels.label_id)\n","nlabels = len(labelencoder.classes_)\n","\n","# merging\n","devicelabels = (deviceapps[['device_id','app']]\n","                .merge(applabels[['app','label']])\n","                .groupby(['device_id','label'])['app'].agg(['size'])\n","                .merge(gatrain[['trainrow']], how='left', left_index=True, right_index=True)\n","                .merge(gatest[['testrow']], how='left', left_index=True, right_index=True)\n","                .reset_index())\n","                \n","# building a feature matrix where the data is all ones, row_ind comes from trainrow or testrow \n","# and col_ind is the encoded label id\n","d = devicelabels.dropna(subset=['trainrow'])\n","Xtr_label = csr_matrix((np.ones(d.shape[0]), (d.trainrow, d.label)),shape=(gatrain.shape[0],nlabels))\n","\n","d = devicelabels.dropna(subset=['testrow'])\n","Xte_label = csr_matrix((np.ones(d.shape[0]), (d.testrow, d.label)),shape=(gatest.shape[0],nlabels))\n","\n","# concatenate all features\n","Xtrain = hstack((Xtr_brand, Xtr_model, Xtr_app, Xtr_label), format='csr')\n","Xtest =  hstack((Xte_brand, Xte_model, Xte_app, Xte_label), format='csr')\n","fulltest = vstack((Xtrain, Xtest))\n","\n","# encoding demographic group\n","#targetencoder = LabelEncoder().fit(gatrain.group)\n","targetencoder = LabelEncoder().fit(y_train)\n","y = targetencoder.transform(y_train)\n","nclasses = len(targetencoder.classes_)\n","\n","# In order to make a good logistic regression model we need to choose a value for \n","# regularization constant C. Smaller values of C mean stronger regularization and \n","# its default value is 1.0. We probably have a lot of mostly useless columns \n","# (rare brands, models or apps), so we'd better look at stronger regularization than default\n","\n","# predict on test data\n","clf = LogisticRegression(C=0.02,multi_class='multinomial',solver='lbfgs')\n","clf.fit(Xtrain, y)\n","pred = pd.DataFrame(clf.predict_proba(fulltest), index = data.index, columns=targetencoder.classes_)\n","\n","# creating a column to indicate which is our predicted group\n","pred['prediction'] = pred.idxmax(axis=1)\n","\n","# merging with the test data to see if we've made the right predictions\n","eva = data.merge(pred, left_index=True, right_index=True)\n","eva = eva[['gender','group','prediction']]\n","eva['predicted gender'] = eva['prediction'].str[0]\n","\n","# comparing actual and predicted gender and group\n","eva['gender result'] = (eva['gender'] == eva['predicted gender']).astype(int)\n","eva['group result'] = (eva['group'] == eva['prediction']).astype(int)\n","\n","# dropping columns that are not needed\n","eva = eva[['prediction','predicted gender','gender result','group result']]\n","\n","# changing column names\n","eva.columns = ['age','gender','gender result','age result']\n","\n","# merging with events table to get latitude and longitude values\n","events = events.set_index('device_id')\n","# first delete all entries in events where lat long is zero or long<70\n","events = events[(events.latitude != 0) & (events.longitude >70)]\n","\n","# then merge and drop duplicate entries\n","final = eva.merge(events, left_index=True, right_index=True, how='inner')\n","final['device id'] = final.index\n","final = final.drop_duplicates('device id',keep='first')\n","\n","# dropping unnecessary columns\n","final = final[['device id','gender','age','latitude','longitude']]\n","\n","# writing result\n","final.to_csv('/content/gdrive/My Drive/MyAnn/Visualization/datafiles/LogisticRegression.csv', index=False)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  mask |= (ar1 == a)\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"],"name":"stderr"}]}]}